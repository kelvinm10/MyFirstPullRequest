{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "26c8529e3b2e59be78d4aa19804373fc",
     "grade": false,
     "grade_id": "title",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# COGS 108 - Assignment 3: Data Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "19a89ebe76d5deeaebb3d494a20c2240",
     "grade": false,
     "grade_id": "important",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Important Reminders\n",
    "\n",
    "- Rename this file to 'A3_$####.ipynb', replacing with your unique ID (first letter of your last name, followed by the last 4 digits of your student ID number), before you submit it. Submit it to TritonED.\n",
    "- Do not change / update / delete any existing cells with 'assert' in them. These are the tests used to check your assignment. \n",
    "    - Changing these will be flagged for attempted cheating. \n",
    "- This assignment has hidden tests: tests that are not visible here, but that will be run on your submitted file. \n",
    "    - This means passing all the tests you can see in the notebook here does not guarantee you have the right answer!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3e5ebfca3f2f8e75fb4d54102698bd77",
     "grade": false,
     "grade_id": "overview",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Overview\n",
    "\n",
    "We have discussed in lecture the importance and the mechanics of protecting individuals privacy when they are included in datasets. \n",
    "\n",
    "One method to do so is the Safe Harbor Method. The Safe Harbour method specifies how to protect individual's identities by telling us which tells us which information to remove from a dataset in order to avoid accidently disclosing personal information. \n",
    "\n",
    "In this assignment, we will explore web scraping, which can often include personally identifiable information, how identity can be decoded from badly anonymized datasets, and also explore using Safe Harbour to anonymize datasets properly. \n",
    "\n",
    "The topics covered in this assignment are mainly covered in the 'DataGathering' and 'DataPrivacy&Anonymization' Tutorial notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ea20266c9be42b2fbdf472d6db1024dd",
     "grade": false,
     "grade_id": "cell-b169d37fcae03fbc",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Installing new packages\n",
    "\n",
    "In the first part of the assignment we will understand how we can scrape the web for data. You have to use the Beautiful Soup library in Python for scraping the data. \n",
    "\n",
    "The library is not installed in Anaconda version, therefore to install a new library for Anaconda, we can use the conda package manager, which the cell below does for you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "dad55181dff84344120ab766c5b62d89",
     "grade": false,
     "grade_id": "cell-8a8f3952c7e67d7f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell to install beautifulsoup4\n",
    "#  You only need to do the installation once\n",
    "#    Once you have run it you can comment these two lines so that the cell doesn't execute everytime.\n",
    "import sys\n",
    "!conda install --yes --prefix {sys.prefix} beautifulsoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1e2ed7d7ab9a2d36798e407ed93e7e11",
     "grade": false,
     "grade_id": "imports",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1d7cc48ec36a10ee8ce4301f4ad8068e",
     "grade": false,
     "grade_id": "import-code",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Imports - these provided for you. Do not import any other packages\n",
    "import pandas as pd\n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2258dd8460e82dd9ba05790b392c2170",
     "grade": false,
     "grade_id": "cell-25153cbdcaad4068",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Part 1: Web Scraping "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1879df607edbde1394ed6b304ba0a2c7",
     "grade": false,
     "grade_id": "cell-76ae256b5f7132b6",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Scraping Rules\n",
    "\n",
    "1) If you are using another organizations website for scraping, make sure to check the website's terms & conditions. \n",
    "\n",
    "2) Do not request data from the website too aggressively (quickly) with your program (also known as spamming), as this may break the website. Make sure your program behaves in a reasonable manner (i.e. acts like a human). One request for one webpage per second is good practice.\n",
    "\n",
    "3) The layout of a website may change from time to time. Because of this, if you're scraping website, make sure to revisit the site and rewrite your code as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4176af1f7152bcb4deff540099f3cfd9",
     "grade": false,
     "grade_id": "cell-f5423577b9902c1c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell will help you understand the permission issues related to accessing a page\n",
    "# Uncomment the two lines, run them, see what error you get, comment them again\n",
    "\n",
    "#page_source = requests.get('http://www.aflcio.org/Legislation-and-Politics/Legislative-Alerts')\n",
    "#page_soup = BeautifulSoup(page_source.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d4fed909c257ed14ed7cf6306ee015f2",
     "grade": false,
     "grade_id": "cell-164e625a3cd53f8d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### What is the error that you got, and why did you get it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d7239e9d93ef503e59cabbee1d3e5481",
     "grade": true,
     "grade_id": "cell-ac79813190d0715c",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "Cannot edit cells above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "a30f65a5cf189bcbb356196ea240d9a5",
     "grade": false,
     "grade_id": "cell-889693bf71daf7c8",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 1a) Web Scrape\n",
    "# We will first retrieve the contents on a page and examine them a bit.\n",
    "\n",
    "# Make a variable called 'wiki', that stores the following URL (as a string):\n",
    "#  'https://en.wikipedia.org/wiki/List_of_U.S._states_and_territories_by_population'\n",
    "# To open the URL you can use 'requests.get' as shown in the cell above. Call this variable 'page'\n",
    "# After that use BeautifulSoup Library to open the URL and assign it to an object called 'soup'\n",
    "\n",
    "wiki = 'https://en.wikipedia.org/wiki/List_of_U.S._states_and_territories_by_population'\n",
    "page = requests.get(wiki)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "88991ab92634826735078f6cba9eb0f1",
     "grade": true,
     "grade_id": "cell-52fad88c14b5f276",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert wiki\n",
    "assert page\n",
    "assert soup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "3625afdb3bb344958bba5e5266366ece",
     "grade": false,
     "grade_id": "cell-4d0a0b26ed667fe0",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of U.S. states and territories by population - Wikipedia\n"
     ]
    }
   ],
   "source": [
    "# 1b) Checking Scrape Contents\n",
    "\n",
    "# Extract the title from the page and save it in a variable called 'title_page'. \n",
    "#  Make sure you extract it as a string.\n",
    "# To do so, you have to use the soup object created in the above cell. \n",
    "#  Hint: from your soup variable, you can access this with '.title.string'\n",
    "# Make sure you print out and check the contents of 'title_page'. \n",
    "#  Note that it should not have any tags (such as '<title>' included in it).\n",
    "title_page = soup.title.string\n",
    "print(title_page)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0ccf61e856e952c8a889f6c03f334321",
     "grade": true,
     "grade_id": "cell-25e2c00e1488f142",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert title_page\n",
    "assert isinstance(title_page, str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "915ab52cbc25de35a1bd5b74bdb1ec95",
     "grade": false,
     "grade_id": "cell-8da7172c1da665fe",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 1c) Extracting Tables\n",
    "\n",
    "# In order to extract the data we want, we'll start with extracting a data table of interest. \n",
    "#  Note that you can see this table by going to look at the link we scraped.\n",
    "# Use the soup object and call a method called find, which will and extract the first table in scraped webpage. \n",
    "#  Note: you need to search for the name 'table', and set the 'class_' argument as 'wikitable sortable'.\n",
    "\n",
    "right_table = soup.find('table', class_ = 'wikitable sortable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "410073a57bc12f34587a7795bbbd852b",
     "grade": true,
     "grade_id": "cell-6a079fac89c3332c",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert right_table\n",
    "assert isinstance(right_table, bs4.element.Tag)\n",
    "assert right_table.name == 'table'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c2d4694252bd5b0f9d973cedba0946e8",
     "grade": false,
     "grade_id": "cell-6219dfad1bd6ba7b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Extract the data from the table into lists.\n",
    "#  Note: This code provided for you. Do read through it and try to see how it works.\n",
    "\n",
    "lst_a, lst_b, lst_c = [], [], []\n",
    "\n",
    "for row in right_table.findAll('tr'):\n",
    "    \n",
    "    cells = row.findAll('td')\n",
    "    \n",
    "    # Skips rows that aren't 10 columns long (like the heading)\n",
    "    if len(cells) != 10:\n",
    "        continue\n",
    "\n",
    "    # This catches when the name cells stops having a link\n",
    "    #  and ends, skipping the last (summary rows)\n",
    "    try:\n",
    "        lst_a.append(cells[2].find('a').text)\n",
    "        lst_b.append(cells[4].find(text=True))\n",
    "        lst_c.append(cells[5].find(text=True))\n",
    "    except:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "4c75c47a485558ac3428c3773830b2ea",
     "grade": false,
     "grade_id": "cell-3b72a498799ef251",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Population Estimate Census Population\n",
      "State                                                         \n",
      "California                        39,536,653        37,252,895\n",
      "Texas                             28,304,596        25,146,105\n",
      "Florida                           20,984,400        18,804,623\n",
      "New York                          19,849,399        19,378,087\n",
      "Pennsylvania                      12,805,537        12,702,887\n",
      "Illinois                          12,802,023        12,831,549\n",
      "Ohio                              11,658,609        11,536,725\n",
      "Georgia                           10,429,379         9,688,681\n",
      "North Carolina                    10,273,419         9,535,692\n",
      "Michigan                           9,962,311         9,884,129\n",
      "New Jersey                         9,005,644         8,791,936\n",
      "Virginia                           8,470,020         8,001,045\n",
      "Washington                         7,405,743         6,724,543\n",
      "Arizona                            7,016,270         6,392,307\n",
      "Massachusetts                      6,859,819         6,547,817\n",
      "Tennessee                          6,715,984         6,346,275\n",
      "Indiana                            6,666,818         6,484,229\n",
      "Missouri                           6,113,532         5,988,927\n",
      "Maryland                           6,052,177         5,773,785\n",
      "Wisconsin                          5,795,483         5,687,289\n",
      "Colorado                           5,607,154         5,029,324\n",
      "Minnesota                          5,576,606         5,303,925\n",
      "South Carolina                     5,024,369         4,625,401\n",
      "Alabama                            4,874,747         4,780,127\n",
      "Louisiana                          4,684,333         4,533,479\n",
      "Kentucky                           4,454,189         4,339,349\n",
      "Oregon                             4,142,776         3,831,073\n",
      "Oklahoma                           3,930,864         3,751,616\n",
      "Connecticut                        3,588,184         3,574,118\n",
      "Puerto Rico                        3,337,177         3,726,157\n",
      "...                                      ...               ...\n",
      "West Virginia                      1,815,857         1,853,011\n",
      "Idaho                              1,716,943         1,567,652\n",
      "Hawaii                             1,427,538         1,360,301\n",
      "New Hampshire                      1,342,795         1,316,466\n",
      "Maine                              1,335,907         1,328,361\n",
      "Rhode Island                       1,059,639         1,052,931\n",
      "Montana                            1,050,493           989,417\n",
      "Delaware                             961,939           897,936\n",
      "South Dakota                         869,666           814,191\n",
      "North Dakota                         755,393           672,591\n",
      "Alaska                               739,795           710,249\n",
      "District of Columbia                 693,972           601,767\n",
      "Vermont                              623,657           625,745\n",
      "Wyoming                              579,315           563,767\n",
      "Guam                                 167,358           159,358\n",
      "U.S. Virgin Islands                  107,268           106,405\n",
      "American Samoa                        51,504            55,519\n",
      "Northern Mariana Islands              52,263            53,883\n",
      "Midway Atoll                              40             2,220\n",
      "Johnston Atoll                             0             1,100\n",
      "Wake Island                              150               382\n",
      "Palmyra Atoll                             20                20\n",
      "Baker Island                               —                 —\n",
      "Howland Island                             0                 —\n",
      "Jarvis Island                              0                 —\n",
      "Kingman Reef                               0                 —\n",
      "Navassa Island                             0                 —\n",
      "Serranilla Bank                            —                 —\n",
      "Bajo Nuevo Bank                            —                 —\n",
      "Contiguous United States         323,551,845       306,687,555\n",
      "\n",
      "[68 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# 1d) Collecting into a dataframe\n",
    "\n",
    "# Create a dataframe 'my_df' and add the data from the lists above to it. \n",
    "#  'lst_a' is the state or territory name. Set the column name as 'State', and make this the index\n",
    "#  'lst_b' is the population estimate. Add it to the dataframe, and set the column name as 'Population Estimate'\n",
    "#  'lst_c' is the census population. Add it to the dataframe, and set the column name as 'Census Population'\n",
    "\n",
    "my_df = pd.DataFrame({'State':lst_a, 'Population Estimate':lst_b, 'Census Population':lst_c}).set_index('State')\n",
    "my_df = my_df[['Population Estimate', 'Census Population']]\n",
    "print(my_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2513c3a8257e82e2789c4709dbf70488",
     "grade": true,
     "grade_id": "cell-406fc7a4b3d93852",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance (my_df, pd.DataFrame)\n",
    "assert my_df.index.name == 'State'\n",
    "assert list(my_df.columns) == ['Population Estimate', 'Census Population']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "04bb731afd119f67f7b280a0c684420b",
     "grade": false,
     "grade_id": "cell-552f1cceb6530fef",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39,536,653\n"
     ]
    }
   ],
   "source": [
    "# 1e) Using the data\n",
    "# What is the Population Estimate of California? Save this answer to a variable called 'calif_pop'\n",
    "# Notes:\n",
    "#  Extract this value programmatically from your dataframe (as in, don't set it explicitly, as 'cf = 123')\n",
    "#    You can use '.loc' to extract a particular value from a dataframe.\n",
    "#  The data in your dataframe will be strings - that's fine, leave them as strings (don't typecast).\n",
    "calif_pop = my_df.loc['California','Population Estimate']\n",
    "print(calif_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "21a3ae96ee9a898e0e1cba4371c9dd11",
     "grade": true,
     "grade_id": "cell-00910bf76609b48e",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert calif_pop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "486c6798edf0e518657ce5e65244601c",
     "grade": false,
     "grade_id": "p1-title",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Part 2: Identifying Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4296e9303d0b9997e5919024b4dc1734",
     "grade": false,
     "grade_id": "p1-desc",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Data Files:\n",
    "- anon_user_dat.json\n",
    "- employee_info.json\n",
    "\n",
    "You will first be working with a file called 'anon_user_dat.json'. This file that contains information about some (fake) Tinder users. When creating an account, each Tinder user was asked to provide their first name, last name, work email (to verify the disclosed workplace), age, gender, phone # and zip code. Before releasing this data, a data scientist cleaned the data to protect the privacy of Tinder's users by removing the obvious personal identifiers: phone #, zip code, and IP address. However, the data scientist chose to keep each users' email addresses because when they visually skimmed a couple of the email addresses none of them seemed to have any of the user's actual names in them. This is where the data scientist made a huge mistake!\n",
    "\n",
    "We will take advantage of having the work email addresses by finding the employee information of different companies and matching that employee information with the information we have, in order to identify the names of the secret Tinder users!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "4cc07f1511b85ba053b9bbc64f9b49c6",
     "grade": false,
     "grade_id": "1a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 2a) Load in the 'cleaned' data \n",
    "\n",
    "# Load the json file into a pandas dataframe. Call it 'df_personal'.\n",
    "df_personal = pd.read_json('anon_user_dat.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "61909bf161ee3e26eaca9c2f1a52fd41",
     "grade": true,
     "grade_id": "1a-tests",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(df_personal, pd.DataFrame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "7fb39c47226cd7f94cc245d51747b746",
     "grade": false,
     "grade_id": "1b",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    gshoreson0@seattletimes.com\n",
      "1             eweaben1@salon.com\n",
      "2        akillerby2@gravatar.com\n",
      "3              gsainz3@zdnet.com\n",
      "4       bdanilewicz4@4shared.com\n",
      "5      sdeerness5@wikispaces.com\n",
      "6         jstillwell6@ustream.tv\n",
      "7         mpriestland7@opera.com\n",
      "8       nerickssen8@hatena.ne.jp\n",
      "9             hparsell9@xing.com\n",
      "Name: email, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 2b) Check the first 10 emails \n",
    "\n",
    "# Save the first 10 emails to a Series, and call it 'sample_emails'. \n",
    "# You should then and print out this Series. \n",
    "# The purpose of this is to get a sense of how these work emails are structured\n",
    "#   and how we could possibly extract where each anonymous user seems to work.\n",
    "\n",
    "sample_emails = pd.Series(df_personal['email'].head(n=10))\n",
    "print(sample_emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e5d7c945a4d2cc76ba068baf15641d43",
     "grade": true,
     "grade_id": "1b-tests",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(sample_emails, pd.Series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "b61be355079651582175dccbace705a5",
     "grade": false,
     "grade_id": "1c",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 2c) Extract the Company Name From the Email \n",
    "\n",
    "# Create a function with the following specifications:\n",
    "#   Function Name: extract_company\n",
    "#   Purpose: to extract the company of the email \n",
    "#          (i.e., everything after the @ sign but before the .)\n",
    "#   Parameter(s): email (string)\n",
    "#   Returns: The extracted part of the email (string)\n",
    "#   Hint: This should take 1 line of code. Look into the find('') method. \n",
    "#\n",
    "# You can start with this outline:\n",
    "#   def extract_company(email):\n",
    "#      return \n",
    "#\n",
    "# Example Usage: \n",
    "#   extract_company(\"larhe@uber.com\") should return \"uber\"\n",
    "#   extract_company(“ds@cogs.edu”) should return “cogs”\n",
    "def extract_company(email):\n",
    "    return email[email.find('@') + 1:email.find('.')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "06225023bd1fad52a5f8e084753af2fb",
     "grade": true,
     "grade_id": "1c-tests",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert extract_company(\"gshoreson0@seattletimes.com\") == \"seattletimes\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2ef7d9e3ecb79343b5b35d3aa70891a8",
     "grade": false,
     "grade_id": "info",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "With a little bit of basic sleuthing (aka googling) and web-scraping (aka selectively reading in html code) it turns out that you've been able to collect information about all the present employees/interns of the companies you are interested in. Specifically, on each company website, you have found the name, gender, and age of its employees. You have saved that info in employee_info.json and plan to see if, using this new information, you can match the Tinder accounts to actual names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "ad3fb36e40e8bb9b629a4d6830c71729",
     "grade": false,
     "grade_id": "1d",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     age      company first_name  gender        last_name\n",
      "0     42      123-reg  Inglebert    Male         Falconer\n",
      "1     14          163     Rafael    Male         Bedenham\n",
      "2     31          163     Lemuel    Male             Lind\n",
      "3     45          163      Penny  Female          Pennone\n",
      "4     52          163       Elva  Female         Crighton\n",
      "5     55         1688   Herminia  Female            Sisse\n",
      "6     30        1und1       Toby  Female           Nisuis\n",
      "7     36        1und1     Kylynn  Female         Vedikhov\n",
      "8     37        1und1     Mychal    None          Denison\n",
      "9     32          360    Angelle  Female           Kupisz\n",
      "10    35          360     Ilario    Male          Mannagh\n",
      "11    41          360     Farley    Male        Mullenger\n",
      "12     5      4shared   Ginnifer  Female           Jarret\n",
      "13    72      4shared      Brody    Male         Pinckard\n",
      "14    30           51     Samara    None           Soares\n",
      "15    50           51     Gillie  Female      Shillinglaw\n",
      "16    70           51    Stanton    Male            Rehme\n",
      "17     8          abc      Lukas    Male             Krol\n",
      "18    22          abc      Glory  Female      Silverthorn\n",
      "19    27        about      Marla  Female          Forsard\n",
      "20    44        about     Karita  Female           Cantos\n",
      "21    57        about    Isidora  Female       Yanyushkin\n",
      "22    61     aboutads   Nikolaus    Male         Haulkham\n",
      "23    34  accuweather   Sinclair    Male         Leverett\n",
      "24    60  accuweather     Ilyssa  Female         Ottewill\n",
      "25    36      addthis     Flossi  Female     Metheringham\n",
      "26    20        admin      Ashby    Male           Gwilym\n",
      "27    52        alexa     Carrol    Male        Terlinden\n",
      "28    14      alibaba    Zebulon    Male          Gasnoll\n",
      "29    38      alibaba     Celina  Female          Santoro\n",
      "..   ...          ...        ...     ...              ...\n",
      "970   40         yale   Violette  Female            Walsh\n",
      "971   48         yale    Bobette  Female         Hurndall\n",
      "972   65         yale    Gwenore  Female            Arens\n",
      "973   72         yale       Mord    Male             Fant\n",
      "974   20       yandex    Lennard    Male           Ducroe\n",
      "975   42       yandex    Garwood    Male          Prophet\n",
      "976   43       yandex    Pernell    Male           Reeman\n",
      "977   57       yandex       Alic    Male         Peachman\n",
      "978   59  ycombinator     Lenore  Female          Broxton\n",
      "979   55   yellowbook   Charlena    None          Johncey\n",
      "980   10  yellowpages        Rab    Male         Goldsack\n",
      "981   24  yellowpages     Berthe  Female     Valentinuzzi\n",
      "982   37  yellowpages    Elliott    Male              Oki\n",
      "983   61  yellowpages     Moises    Male         Lansdale\n",
      "984   15     yolasite       Gale    Male           Boorne\n",
      "985   34     yolasite     Briney  Female  Grafton-Herbert\n",
      "986   25        youku  Philomena  Female        Cranstoun\n",
      "987   32        youku     Dianna  Female        Handyside\n",
      "988   41        youku        May  Female         Sellwood\n",
      "989   50        youku    Humfrey    Male         Wheelton\n",
      "990   56        youku   Marchall    Male           Bilbee\n",
      "991   38        youtu    Carroll  Female       Bertwistle\n",
      "992   39        youtu  Claudette  Female          Gabotti\n",
      "993   65        youtu      Tyler    Male       Giacovazzo\n",
      "994    3      youtube     Herman    Male          Dhennin\n",
      "995   46        zdnet      Guido    Male          Comfort\n",
      "996   48        zdnet      Biron    Male        Malkinson\n",
      "997   27       zimbio      Becka  Female            Waryk\n",
      "998   34       zimbio   Andreana  Female          Ladewig\n",
      "999   75       zimbio     Jobyna  Female            Busek\n",
      "\n",
      "[1000 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# 2d) Load in employee data \n",
    "\n",
    "# Load the json file into a pandas dataframe. Call it 'df_employee'.\n",
    "df_employee = pd.read_json('employee_info.json')\n",
    "print(df_employee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "cd93c56e6879c7b8b50c7317bd3e1246",
     "grade": true,
     "grade_id": "1d-tests",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(df_employee, pd.DataFrame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "fc07ea1ae1be13b991d48f428cac7b37",
     "grade": false,
     "grade_id": "1e",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Maxwell'], ['Jorio'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2e) Match the employee name with company, age, gender \n",
    "\n",
    "# Create a function with the following specifications:\n",
    "#   Function name: employee_matcher\n",
    "#   Purpose: to match the employee name with the provided company, age, and gender\n",
    "#   Parameter(s): company (string), age (int), gender (string)\n",
    "#   Returns: The employee first_name and last_name like this: return first_name, last_name \n",
    "#   Note: If there are multiple employees that fit the same description, first_name and \n",
    "#         last_name should return a list of all possible first names and last name\n",
    "#         i.e., ['Desmund', 'Kelby'], ['Shepley', 'Tichner']\n",
    "#\n",
    "# Hint:\n",
    "# There are many different ways to code this.\n",
    "# 1) An unelegant solution is to loop through df_employee \n",
    "#    and for each data item see if the company, age, and gender match\n",
    "#    i.e., for i in range(0, len(df_employee)):\n",
    "#              if (company == df_employee.ix[i,'company']):\n",
    "#\n",
    "# However! The solution above is very inefficient and long, \n",
    "# so you should try to look into this:\n",
    "# 2) Google the df.loc method: It extracts pieces of the dataframe\n",
    "#    if it fulfills a certain condition.\n",
    "#    i.e., df_employee.loc[df_employee['company'] == company]\n",
    "#    If you need to convert your pandas data series into a list,\n",
    "#    you can do list(result) where result is a pandas \"series\"\n",
    "# \n",
    "# You can start with this outline:\n",
    "#   def employee_matcher(company, age, gender):\n",
    "#      return first_name, last_name\n",
    "\n",
    "def employee_matcher(company, age, gender):\n",
    "    df = df_employee.loc[df_employee['company']== company]\n",
    "    df = df.loc[df_employee['age']== age]\n",
    "    df = df.loc[df_employee['gender']==gender]\n",
    "    first_name = list(df['first_name'])\n",
    "    last_name = list(df['last_name'])\n",
    "    return first_name, last_name\n",
    "employee_matcher(\"google\", 41, \"Male\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3f713cf00c84495d3bea5ba76d0f7e6a",
     "grade": true,
     "grade_id": "1e-tests",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert employee_matcher(\"google\", 41, \"Male\") == (['Maxwell'], ['Jorio'])\n",
    "assert employee_matcher(\"salon\", 47, \"Female\") == (['Elenore'], ['Gravett'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "eb565b364684e43f855d5ff731384879",
     "grade": false,
     "grade_id": "1f",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/KelvinM/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# 2f) Extract all the private data \n",
    "\n",
    "# - Create 2 empty lists called 'first_names' and 'last_names'\n",
    "# - Loop through all the people we are trying to identify in df_personal\n",
    "# - Call the extract_company function (i.e., extract_company(df_personal.ix[i, 'email']) )\n",
    "# - Call the employee_matcher function \n",
    "# - Append the results of employee_matcher to the appropriate lists (first_names and last_names)\n",
    "\n",
    "first_names = list()\n",
    "last_names = list()\n",
    "for ind, row in df_personal.iterrows():\n",
    "    company = extract_company(df_personal.ix[ind,'email'])\n",
    "    [f_name, l_name] = employee_matcher(company, row['age'], row['gender'])\n",
    "    first_names.append(f_name)\n",
    "    last_names.append(l_name)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "60add6c068758eb6abcaa30879d2b7af",
     "grade": true,
     "grade_id": "1f-tests",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert first_names[45:50]== [['Justino'], ['Tadio'], ['Kennith'], ['Cedric'], ['Amargo']]\n",
    "assert last_names[45:50] == [['Corro'], ['Blackford'], ['Milton'], ['Yggo'], ['Grigor']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "797556598e2b8c2406f949635a108850",
     "grade": false,
     "grade_id": "1g",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 2g) Add the names to the original 'secure' dataset! \n",
    "\n",
    "# We have done this last step for you below, all you need to do is run this cell.\n",
    "# For your own personal enjoyment, you should also print out\n",
    "#   the new df_personal with the identified people. \n",
    "\n",
    "df_personal['first_name'] = first_names\n",
    "df_personal['last_name'] = last_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "220e03ead46597189f618c88f0088bcc",
     "grade": false,
     "grade_id": "wrap-p1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "We have now just discovered the 'anonymous' identities of all the registered Tinder users...awkward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "975e9008d46096fe811a216ea5f2b0d3",
     "grade": false,
     "grade_id": "p2-title",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Part 3: Anonymize Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "28f7733eb649c467c1e05df6a0287439",
     "grade": false,
     "grade_id": "p2-desc",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "You are hopefully now convinced that with some seemingly harmless data a hacker can pretty easily discover the identities of certain users. Thus, we will now clean the original Tinder data ourselves according to the Safe Harbor Method in order to make sure that it has been *properly* cleaned..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "89e65ce9092dc3ace07ed9f7e32b2fc1",
     "grade": false,
     "grade_id": "2a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     age                           email first_name  gender       ip_address  \\\n",
      "0     60     gshoreson0@seattletimes.com     Gordon    Male    230.97.219.70   \n",
      "1     47              eweaben1@salon.com    Elenore  Female   202.253.80.173   \n",
      "2     27         akillerby2@gravatar.com       Abbe    Male    15.120.128.79   \n",
      "3     46               gsainz3@zdnet.com      Guido    Male   71.234.147.178   \n",
      "4     72        bdanilewicz4@4shared.com      Brody    Male   68.192.188.136   \n",
      "5     46       sdeerness5@wikispaces.com     Shalne  Female    204.227.6.124   \n",
      "6     53          jstillwell6@ustream.tv      Joell  Female   37.146.221.194   \n",
      "7     29          mpriestland7@opera.com    Manfred    Male     67.64.181.77   \n",
      "8     39        nerickssen8@hatena.ne.jp     Neille  Female   180.183.192.79   \n",
      "9     45              hparsell9@xing.com      Henri    Male    32.181.36.170   \n",
      "10    26                 acopasa@fda.gov    Alyosha    Male   36.177.179.182   \n",
      "11    83        bdanielovitchb@jigsy.com     Berkie    Male    86.81.145.219   \n",
      "12    73              cwestbergc@psu.edu    Caresse  Female     28.243.72.29   \n",
      "13    30          jlarived@goodreads.com         Jo  Female     165.251.5.90   \n",
      "14    69             mchallisse@ning.com   Marcelia  Female   148.248.57.176   \n",
      "15    29            cbrognotf@ebay.co.uk       Clim    Male    39.47.253.182   \n",
      "16    45              aphearg@tumblr.com      Arnie    Male    88.180.58.248   \n",
      "17     3             askogginsh@jugem.jp     Astrix  Female    208.161.20.23   \n",
      "18    34       eondraseki@deviantart.com  Enriqueta  Female     1.26.229.204   \n",
      "19    37                 kcaswallj@is.gd    Kristen  Female    30.161.15.205   \n",
      "20    53          cpetrillok@cbsnews.com     Cletis    Male    205.38.38.180   \n",
      "21    58             bstratfordl@ted.com  Bernadine  Female    159.77.18.200   \n",
      "22    83     mandreichikm@shareasale.com       Mack    Male   37.233.225.215   \n",
      "23    47              jsegarn@sfgate.com      Jonas    Male   45.144.205.179   \n",
      "24    51        aurridgeo@purevolume.com    Antoine    Male    101.79.179.65   \n",
      "25    65                njandap@ebay.com    Nichols    Male    155.44.138.46   \n",
      "26    26             lwathallq@exblog.jp      Lorie  Female   79.106.191.247   \n",
      "27    57      aoveringtonr@canalblog.com     Alissa  Female     148.136.49.1   \n",
      "28    39                dbrellins@ft.com       Dona  Female     82.233.62.39   \n",
      "29    26              ebukact@toplist.cz       Essa  Female  191.180.218.203   \n",
      "..   ...                             ...        ...     ...              ...   \n",
      "970   47        dsessionsqy@sakura.ne.jp     Dehlia  Female      4.190.6.161   \n",
      "971   25      vkondratenkoqz@cornell.edu       Vick    Male  142.247.110.109   \n",
      "972   43         tbrethertonr0@lycos.com      Tilda  Female   110.232.61.135   \n",
      "973   65        srenfrewr1@shinystat.com     Stacey  Female  100.110.251.127   \n",
      "974   47       jjoiceyr2@theatlantic.com     Justin    Male   111.102.229.23   \n",
      "975   20           bborleacer3@naver.com       Beck    Male   235.145.58.208   \n",
      "976   33         lmackeer4@reference.com      Lilla  Female   134.25.245.204   \n",
      "977   37         mpaolicchir5@utexas.edu     Mellie  Female   134.131.44.209   \n",
      "978   52              lgaliar6@lycos.com    Laverne  Female    119.36.146.55   \n",
      "979   25  ldemcakr7@networksolutions.com        Lee  Female    62.235.73.154   \n",
      "980   35            ide giorgior8@360.cn     Ilario    Male  221.122.195.221   \n",
      "981   41            mmctrustyr9@jugem.jp     Merell    Male    27.180.39.146   \n",
      "982   63           ekohnra@amazonaws.com       Elia    Male  219.249.104.182   \n",
      "983   35        mmillmorerb@hatena.ne.jp      Minor    Male    28.203.151.80   \n",
      "984   20           lchaudrellerc@soup.io        Lon    Male   41.164.159.120   \n",
      "985   43            iavramovitzrd@ft.com        Ivy  Female  156.241.220.163   \n",
      "986   32         rreaneyre@canalblog.com       Rory  Female      88.61.92.34   \n",
      "987   30    sscawnrf@businessinsider.com    Sampson    Male    167.100.18.51   \n",
      "988   48         lharbronrg@slashdot.org      Levey    Male  247.242.143.144   \n",
      "989   37              pgurnayrh@uiuc.edu    Padgett    Male    232.159.28.11   \n",
      "990   31                 ckyngeri@hp.com    Chryste  Female   158.126.242.37   \n",
      "991   55     cboothroydrj@yellowbook.com   Charlena    None    164.13.253.57   \n",
      "992   14             kbrunkerrk@hibu.com       Keen    Male    228.227.8.245   \n",
      "993   65             sleallerl@wikia.com      Selle  Female     42.147.60.17   \n",
      "994   38          kbeefonrm@vkontakte.ru    Karylin  Female     22.178.83.93   \n",
      "995    3           pstroulgerrn@time.com   Penelopa  Female  116.139.135.110   \n",
      "996   49     kbasnettro@seattletimes.com      Kandy  Female    204.88.246.32   \n",
      "997   75     pmortlockrp@liveinternet.ru       Paco    Male   223.217.138.28   \n",
      "998   81            sphetterq@toplist.cz      Sammy    Male    30.133.159.63   \n",
      "999   70           jtyresrr@slashdot.org     Josiah    Male    82.208.90.242   \n",
      "\n",
      "       last_name          phone    zip  \n",
      "0      DelaField  (245)663-9899   6705  \n",
      "1        Gravett  (445)749-6402  40330  \n",
      "2      Stockdale  (312)997-8947  44139  \n",
      "3        Comfort  (530)815-7417  44201  \n",
      "4       Pinckard  (214)138-6981  72956  \n",
      "5          Smail  (918)972-0284  53086  \n",
      "6    Bowlesworth  (113)112-6771  52073  \n",
      "7        Bricket  (665)414-5000  92617  \n",
      "8        McCahey  (218)925-2761  55027  \n",
      "9     Scotchford  (433)404-7429  74647  \n",
      "10       Scollan  (375)464-4912  50255  \n",
      "11    Ciementini  (678)997-5536  97842  \n",
      "12       Cubbino  (920)742-0040  97004  \n",
      "13      Grangier  (928)244-7440  37821  \n",
      "14       Dimitru  (727)125-0315  93255  \n",
      "15        Roddam  (185)375-0188  98068  \n",
      "16         Raoux  (805)542-0438   8074  \n",
      "17        Grooby  (841)267-7102  20005  \n",
      "18       Raggles  (639)538-7115  42347  \n",
      "19       Vennart  (104)768-2999  52768  \n",
      "20      Gulliman  (274)183-1917  73150  \n",
      "21     La Padula  (981)342-5337  57313  \n",
      "22     Hanwright  (605)741-2122  88052  \n",
      "23        Checci  (460)335-2421  60073  \n",
      "24       Lukovic  (996)835-2682  44010  \n",
      "25     Flintoffe  (919)465-9344  55438  \n",
      "26        Jeskin  (517)796-3878  70726  \n",
      "27     Ganforthe  (175)703-9055  72576  \n",
      "28     Dumberell  (666)800-4626  96161  \n",
      "29       Kaveney  (802)233-2511  34639  \n",
      "..           ...            ...    ...  \n",
      "970         Ades  (877)340-3983  81631  \n",
      "971       Ketley  (691)781-9582  23146  \n",
      "972      Cossins  (323)288-9679  79530  \n",
      "973      Quinion  (452)309-2781  74726  \n",
      "974     Bockings  (498)521-4884  22579  \n",
      "975      Jerrand  (871)168-1695  50315  \n",
      "976        Pyffe  (646)378-6618  18037  \n",
      "977      Airdrie  (691)913-9932  74054  \n",
      "978        Flint  (792)766-3084  47270  \n",
      "979        Vasic  (626)210-9784  66023  \n",
      "980      Mannagh  (501)588-7995  95113  \n",
      "981          Kop  (532)164-3700  16508  \n",
      "982     Stedmond  (160)896-8551  47515  \n",
      "983     Kynaston  (312)645-4661  80654  \n",
      "984       Dyster  (142)357-9842  54234  \n",
      "985        Cardo  (690)781-2853   1022  \n",
      "986       Jersch  (461)911-4511  30176  \n",
      "987      Wrangle  (275)423-6242  19119  \n",
      "988        Towle  (828)103-0054  95492  \n",
      "989        Angus  (214)353-4128  88411  \n",
      "990   Kennington  (443)231-5097   1568  \n",
      "991      Johncey  (746)900-3948  98548  \n",
      "992    MacDermot  (602)869-5523  50431  \n",
      "993     Burleton  (320)646-8913  58005  \n",
      "994      Crosbie  (519)281-1309   1826  \n",
      "995        Roman  (267)574-3068  82944  \n",
      "996       Cossam  (790)556-4502  10455  \n",
      "997  Weatherburn  (267)644-8957  63940  \n",
      "998       Dymick  (146)538-5595  24265  \n",
      "999     Ayshford  (571)127-0586  61774  \n",
      "\n",
      "[1000 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# 3a) Load in personal data \n",
    "\n",
    "# Load the user_dat.json file into a pandas dataframe. Call it 'df_users'.\n",
    "# Note: You might find that using the same method as A2 (or above) leads to an error.\n",
    "# The file has a slightly different organization. \n",
    "#   Try googling the error and finding the fix for it.\n",
    "# Hint: you can still use 'pd.read_json', you just need to add another argument.\n",
    "\n",
    "df_users = pd.read_json('user_dat.json',lines = True) \n",
    "print(df_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5ec60d4634be90d7f87fd0bd248755cd",
     "grade": true,
     "grade_id": "2a-tests",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(df_users, pd.DataFrame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "912a843843c85ea7007bfa6fe034ecb0",
     "grade": false,
     "grade_id": "2b",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 3b) Drop personal attributes \n",
    "\n",
    "# Remove any personal information, following the Safe Harbour method.\n",
    "# Based on the Safe Harbour method, remove any columns from df_users that contain personal information.\n",
    "#   Note that details on the Safe Harbour method are covered in the Tutorials.\n",
    "df_users = df_users.drop('email', axis=1)\n",
    "df_users = df_users.drop('first_name', axis=1)\n",
    "df_users = df_users.drop('last_name', axis=1)\n",
    "df_users = df_users.drop('phone',axis=1)\n",
    "df_users = df_users.drop('ip_address',axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "aaaa4402b823f36919d4953dcd89ebba",
     "grade": true,
     "grade_id": "2b-tests",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(df_users.columns) == 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "2055761795183edb7258b03b76270898",
     "grade": false,
     "grade_id": "2c",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 3c) Drop ages that are above 90 \n",
    "\n",
    "# Safe Harbour rule C:\n",
    "#   Drop all the rows which have age greater than 90 from df_users\n",
    "df_users.drop(df_users[df_users.age > 90].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0bf95b9f32e8c6f695d2850814459daa",
     "grade": true,
     "grade_id": "2c-tests",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert df_users.shape == (993, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "f4745cc6348949495135886a90078d9d",
     "grade": false,
     "grade_id": "2d",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         zip  population\n",
      "0      01001       16769\n",
      "1      01002       29049\n",
      "2      01003       10372\n",
      "3      01005        5079\n",
      "4      01007       14649\n",
      "5      01008        1263\n",
      "6      01009         741\n",
      "7      01010        3609\n",
      "8      01011        1370\n",
      "9      01012         661\n",
      "10     01013       23188\n",
      "11     01020       29668\n",
      "12     01022        2451\n",
      "13     01026         946\n",
      "14     01027       17660\n",
      "15     01028       15720\n",
      "16     01029         789\n",
      "17     01030       11669\n",
      "18     01031        1308\n",
      "19     01032         570\n",
      "20     01033        6227\n",
      "21     01034        2021\n",
      "22     01035        5250\n",
      "23     01036        5109\n",
      "24     01037         838\n",
      "25     01038        2545\n",
      "26     01039        1336\n",
      "27     01040       39880\n",
      "28     01050        2530\n",
      "29     01053        1685\n",
      "...      ...         ...\n",
      "33062  99786         259\n",
      "33063  99788          69\n",
      "33064  99789         402\n",
      "33065  99790          20\n",
      "33066  99791         237\n",
      "33067  99801       29164\n",
      "33068  99820         479\n",
      "33069  99824        2111\n",
      "33070  99825         120\n",
      "33071  99826         442\n",
      "33072  99827        2602\n",
      "33073  99829         777\n",
      "33074  99830         561\n",
      "33075  99832         104\n",
      "33076  99833        3202\n",
      "33077  99835        8880\n",
      "33078  99836          52\n",
      "33079  99840         968\n",
      "33080  99841         133\n",
      "33081  99901       13508\n",
      "33082  99903          31\n",
      "33083  99918         231\n",
      "33084  99919         531\n",
      "33085  99921        1920\n",
      "33086  99922         384\n",
      "33087  99923          87\n",
      "33088  99925         819\n",
      "33089  99926        1460\n",
      "33090  99927          94\n",
      "33091  99929        2338\n",
      "\n",
      "[33092 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# 3d) Load in zip code data \n",
    "\n",
    "# Load the zip_pop.csv file into a (different) pandas dataframe. Call it 'df_zip'.\n",
    "# Note that the zip data should be read in as strings, not ints, as would be the default. \n",
    "# In read_csv, use the parameter 'dtype' to specify to read 'zip' as str, and 'population' as int.\n",
    "df_zip = pd.read_csv('zip_pop.csv', dtype={'zip':str, 'population':int})\n",
    "print(df_zip)\n",
    "df_zip.drop_duplicates('zip', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "78a50c8e93d6577339c9611bdd7eaaa8",
     "grade": true,
     "grade_id": "2d-tests",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(df_zip, pd.DataFrame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "9cc339bd36e3b2c3813c6852608d87cc",
     "grade": false,
     "grade_id": "2e",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 3e) Sort zipcodes into \"Geographic Subdivision\" \n",
    "\n",
    "# The Safe Harbour Method applies to \"Geographic Subdivisions\"\n",
    "#   as opposed to each zipcode itself. \n",
    "# Geographic Subdivision:\n",
    "#   All areas which share the first 3 digits of a zip code\n",
    "#\n",
    "# Count the total population for each geographic subdivision\n",
    "# Warning: you have to be savy with a dictionary here\n",
    "# To understand how a dictionary works, check the section materials,\n",
    "#   use google and go to discussion sections!\n",
    "#\n",
    "# Instructions: \n",
    "# - Create an empty dictionary: zip_dict = {}\n",
    "# - Loop through all the zip_codes in df_zip\n",
    "# - Create a dictionary key for the first 3 digits of a zip_code in zip_dict\n",
    "# - Continually add population counts to the key that contains the \n",
    "#     same first 3 digits of the zip code\n",
    "#\n",
    "# To extract the population you will find this code useful:\n",
    "#   population = list(df_zip.loc[df_zip['zip'] == zip_code]['population'])\n",
    "# To extract the first 3 digits of a zip_code you will find this code useful:\n",
    "#   int(str(zip_code)[:3])\n",
    "#\n",
    "# Note: this code may take some time (many seconds, up to a minute or two) to run\n",
    "zip_dict = {}\n",
    "for zip_code in df_zip['zip']:\n",
    "    population = list(df_zip.loc[df_zip['zip'] == zip_code]['population'])\n",
    "    zip_num = int(str(zip_code)[:3])\n",
    "    zip_dict.setdefault(zip_num,0)\n",
    "    zip_dict[zip_num] = population[0] + zip_dict[zip_num]\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2bd97a39d94617052c6bb3cc8c5bd497",
     "grade": true,
     "grade_id": "2e-tests",
     "locked": true,
     "points": 1.25,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(zip_dict, dict)\n",
    "assert zip_dict[100] == 1502501\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4dcaab99a0cd491db53cc2842f3d750f",
     "grade": false,
     "grade_id": "2f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 3f) Explain this code excerpt \n",
    "# Note: you do not have to use this line of code at this point in the assignmnet.\n",
    "#  It is one of the lines provided to you in 2e. Here, just write a quick comment on what it does. \n",
    "\n",
    "# In the cell below, explain in words what what the following line of code is doing:\n",
    "population = list(df_zip.loc[df_zip['zip'] == zip_code]['population'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "cc98e43035f0175d3f82fe6a94dc5f58",
     "grade": true,
     "grade_id": "2f-write",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "This code is locating elements in the 'zip' column and making sure they are equal to zip_code. After doing this, the corresponding population number is extracted to a list, and the process continues for all elements in the 'zip' column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "621d2ead4f68903eaa2ddadbf4f64459",
     "grade": false,
     "grade_id": "2g",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 3g) Masking the Zip Codes \n",
    "\n",
    "# In this part, you should write a for loop, updating the df_users dataframe.\n",
    "# Go through each user, and update their zip-code, to Safe Harbour specifications:\n",
    "#   If the user is from a zip code for the which the\n",
    "#     \"Geographic Subdivision\" is less than equal to 20000:\n",
    "#        - Change the zip code to 0 \n",
    "#   Otherwise:\n",
    "#         - Change the zip code to be only the first 3 numbers of the full zip cide\n",
    "# Do all this re-writting the zip_code columns of the 'df_users' DataFrame\n",
    "#\n",
    "# Hints:\n",
    "#  - This will be several lines of code, looping through the DataFrame, \n",
    "#      getting each zip code, checking the geographic subdivision with \n",
    "#      the population in zip_dict, and settig the zip_code accordingly. \n",
    "for ind, row in df_users.iterrows():\n",
    "    zip_code = row['zip']\n",
    "    key = int(str(zip_code)[:3])\n",
    "    if zip_dict[key] <= 20000:\n",
    "         new_zip = 0\n",
    "    else: \n",
    "         new_zip = key\n",
    "    df_users.loc[ind, 'zip'] = new_zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "96ef0f83802b7b170238228b68be36e1",
     "grade": true,
     "grade_id": "2g-tests",
     "locked": true,
     "points": 1.25,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(df_users) == 993\n",
    "assert sum(df_users.zip == 0) == 7\n",
    "assert df_users.loc[671, 'zip'] == 359\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "a0313df0a86a0d1c0f762fadfa8fc80d",
     "grade": false,
     "grade_id": "2h",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 3h) Save out the properly anonymized data to json file \n",
    "\n",
    "# Save out df_users as a json file, called 'real_anon_user_dat.json'\n",
    "\n",
    "df_users.to_json('real_anon_user_dat.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5f1b809a9d61919bc0dd68fda1aedc1b",
     "grade": true,
     "grade_id": "2h-tests",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(pd.read_json('real_anon_user_dat.json'), pd.DataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d2d93ad8046edf965c498ec0bf27f765",
     "grade": false,
     "grade_id": "finish",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Congrats, you're done! The users identities are much more protected now. \n",
    "\n",
    "Submit this notebook file to TritonED."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
